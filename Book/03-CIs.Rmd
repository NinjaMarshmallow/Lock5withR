<!-- r set_parent('Lock5withR.Rnw') -->
```{r include=FALSE}
require(Lock5withR)
require("fastR")
```

`r chapter <- 2`
# Confidence Intervals

## Sampling Distributions

The key idea in this chapter is the notion of a sampling distribution.  Do not confuse it with 
the population (what we would like to know about) or the sample (what we actually have data about). If we could repeatedly sample from a population, and if we computed a statistic from each sample, the distribution of those statistics would be the sampling distribution.  Sampling distributions tell us how things vary from sample to sample and are the key to interpreting data.

<!-- Example 3.1 -->
<!-- Example 3.2 -->
<!-- Example 3.3 -->
### Variability of Sample Statistics {-}

#### Example 3.4 {-}
```{r Example3.4}
head(StatisticsPhD)
mean(~FTGradEnrollment, data = StatisticsPhD) # mean enrollment in original population
```


#### Example 3.5 {-}

To select a random sample of a certain size in R  we can use the `sample()` function.
```{r Example3.5, cache=TRUE}
sample10 <- sample(StatisticsPhD, 10); sample10
x.bar <- mean(~FTGradEnrollment, data = sample10); x.bar  # mean enrollment in sample10
```

Note that this sample has been assigned a name to which we can refer back to find the mean of that particular sample.

```{r "Example3.5b", cache=TRUE}
mean(~FTGradEnrollment, data = sample(StatisticsPhD, 10))  # mean enrollment in another sample 
```


```{r Table3.2, ref.label = "Example3.5", include=FALSE}
```

```{r Table3.3, ref.label = "Example3.5", include=FALSE}
```


#### Figure 3.1 {-}

We should check that that our sample distribution has an appropriate shape:
```{r Figure3.1, opts.label="fig4", cache=TRUE}
# Now we'll do it 1000 times
Sampledist <- do(1000) * mean( ~ FTGradEnrollment, data = sample(StatisticsPhD, 10))
head(Sampledist, 3)
gf_dotplot( ~ mean, binwidth = .9, data = Sampledist)
```

<!-- AuthNote --- should be count not density -->

In many (but not all) situations, the sampling distribution is 
<!-- begin itemize -->

#. unimodal,
#. symmetric, and
#. bell-shaped (The technical phrase is "approximately normal".)
<!-- end itemize -->

#### Example 3.6 {-}

This time we don't have data, but instead we have a summary of the data. We can however, still simulate the sample distribution by using the `rflip()` function.
```{r Example3.6, opts.label = "fig4", cache = TRUE}
Sampledist.deg <- do(1000) * rflip(200, 0.275) # 1000 samples, each of size 200 and proportion 0.275
head(Sampledist.deg, 3)
gf_dotplot(~ prop, binwidth = .002, data = Sampledist.deg)
```


```{r Figure3.2, ref.label = "Example3.6", include=FALSE}
```


### Measuring Sampling Variability: The Standard Error {-}


----

  The standard deviation of a sampling distribution is called the **standard error**, 
	denoted $SE$.

----


The standard error is our primary way of measuring how much variability there is from sample statistic to sample statistic, and therefore how precise our estimates are.

#### Example 3.7 {-}

Calculating the SE is the same as calculating the standard deviation of a sampling distribution, so we use `sd()`.
```{r Example3.7}
SE <- sd( ~ mean, data = Sampledist); SE    # sample from Example 3.5
SE2 <- sd(~prop, data = Sampledist.deg); SE2     # sample from Example 3.6
```


<!-- Example 3.8 -->


### The Importance of Sample Size {-}

#### Example 3.9 {-}

```{r Example3.9}
Sampledist.1000 <- do(1000) * rflip(1000, 0.275) # 1000 samples, each of size 1000 and proportion 0.275
Sampledist.200 <- do(1000) * rflip(200, 0.275)   # 1000 samples, each of size 200 and proportion 0.275
Sampledist.50 <- do(1000) * rflip(50, 0.275)     # 1000 samples, each of size 50 and proportion 0.275
```


#### Figure 3.3 {-}

```{r Figure3.3, opts.label="fig3"}
gf_dotplot(~ prop, binwidth = .0025, data = Sampledist.1000) %>% gf_lims(
  x = c(.05,.5), y = c(0, 150))
gf_dotplot(~ prop, binwidth = .003, data = Sampledist.200) %>% gf_lims(
  x = c(.05,.5), y = c(0, 60))
gf_dotplot(~ prop, binwidth = .0015, data = Sampledist.50) %>% gf_lims(
  x = c(.05,.5), y = c(0, 150))
```


<!-- Example 3.10 -->
<!-- Example 3.11 -->

## Understanding and Interpreting Confidence Intervals

### Interval Estimates and Margin of Error {-}


----

An **interval estimate** 
gives a range of plausible values for a population parameter.  

----


This is better than a single number (also called a point estimate) because it gives some indication of the precision of the estimate.

One way to express an interval estimate is with a point estimate and a **margin of error**.

We can convert margin of error into an interval by adding and subtracting the margin of error to/from the statistic.

#### Example 3.12 {-}

```{r Example3.12, tidy=FALSE}
p.hat <- 0.42                       # sample proportion
MoE <- 0.03                         # margin of error
p.hat - MoE                         # lower limit of interval estimate
p.hat + MoE                         # upper limit of interval estimate
```


#### Example 3.13 {-}

```{r Example3.13, tidy=FALSE}
p.hat <- 0.54                       # sample proportion
MoE <- 0.02                         # margin of error
p.hat - MoE                         # lower limit of interval estimate
p.hat + MoE                         # upper limit of interval estimate
```


```{r Example3.13b}
p.hat <- 0.54 
MoE <- 0.10
p.hat - MoE
p.hat + MoE
```


### Confidence Intervals {-}


----

A confidence interval for a parameter is an interval computed from sample data
by a method that will capture the parameter for a specified proportion of all
samples

----


<!-- begin enumerate -->

#. The probability of correctly containing the parameter is called the coverage rate or **confidence level**.
#. So 95% of 95% confidence intervals contain the parameter being estimated.
#. The margins of error in the tables above were designed to produce 95% confidence intervals.
<!-- end enumerate -->

#### Example 3.14 {-}

```{r Example3.14, tidy=FALSE}
x.bar <- 61.5              # given sample mean
SE <- 11                   # given estimated standard error
MoE <- 2 * SE; MoE         # margin of error for 95<!--  CI -->
x.bar - MoE                # lower limit of 95<!--  CI -->
x.bar + MoE                # upper limit of 95<!--  CI -->
```


### Understanding Confidence Intervals {-}

#### Example 3.15 {-}

```{r Example3.15}
SE <- 0.03
p1 <- 0.26 
p2 <- 0.32
p3 <- 0.20
MoE <- 2 * SE
```


```{r Example3.15b}
p1-MoE
p1+MoE
p2-MoE
p2+MoE
p3-MoE
p3+MoE
```


#### Figure 3.12 {-}

```{r Figure3.12, opts.lable="fig4"}
p <- 0.275
SE <- 0.03
MoE <- 2 * SE
p - MoE
p + MoE
gf_dotplot(~ prop, binwidth = .002, dotsize = .8, colour = ~(0.215 <= prop & prop <= 0.335), data = Sampledist.deg, show.legend = FALSE)
```

Notice how we defined groups in this dotplot. We are grouping proportions that less than 0.215 and more than 0.335.
<!-- AuthNote --- this is how it was done in the previous tutorial with lattice, would it be better to create a new variable in the data and use that instead? -->

#### Figure 3.13 {-}

We can create the data needed for plots like Figure 3.13 using `CIsim()`.  
<!--  The plot itself uses `xYplot()` from the **`Hmisc`** package. -->
```{r Figure3.13, message=FALSE, seed=1234, opts.label="fig1"}
CIsim(200, samples = 3, rdist = rbinom, args = list(size = 1, prob = 0.275), 
      method = binom.test, method.args = list(success = 1), 
	  verbose = FALSE, estimand = 0.275)
```

<!-- require(Hmisc) -->
<!-- xYplot(Cbind(estimate, lower, upper) ~ sample, -->
<!--   data=results, -->
<!--   par.settings=col.mosaic(),  -->
<!--   groups=cover) -->

```{r Figure3.13b, message=FALSE, seed=1234, opts.label="fig1"}
CIsim(200, samples = 100, rdist = rbinom, args = list(size = 1, prob = 0.275), 
      method = binom.test, method.args = list(success = 1), 
	  verbose = FALSE, estimand = 0.275)
```

<!-- require(Hmisc) -->
<!-- xYplot(Cbind(estimate, lower, upper) ~ sample, -->
<!--   data=results, -->
<!--   par.settings=col.mosaic(),  -->
<!--   groups=cover) -->

### Interpreting Confidence Intervals {-}

#### Example 3.16 {-}

```{r Example3.16}
x.bar <- 27.655
SE <- 0.009
MoE <- 2 * SE
x.bar - MoE
x.bar + MoE
```


#### Example 3.17 {-}

```{r Example3.17}
diff.x <- -1.915
SE <- 0.016
MoE <- 2 * SE
diff.x - MoE
diff.x + MoE
```


<!-- Example 3.18 -->

## Constructing Bootstrap Confidence Intervals

Here's the clever idea:  We don't have the population, but we have a sample.  Probably the sample it similar to the population in many ways.  So let's sample from our sample.  We'll call it **resampling** (also called **bootstrapping**). We want samples the same size as our original sample, so we will need to sample with replacement.  This means that we may pick some members of the population more than once and others not at all.  We'll do this many times, however, so each member of our sample will get its fair share. (Notice the similarity to and difference from sampling from populations in the previous sections.) 

#### Figure 3.14 {-}

```{r Figure3.14}
gf_dotplot(~Time, binwidth = 1, data = CommuteAtlanta)
```


### Bootstrap Samples

#### Table 3.7 {-}

The computer can easily do all of the resampling by using the `resample()`.
```{r Table3.7}
mean(~Time, data = resample(CommuteAtlanta)) # mean commute time in one resample
mean(~Time, data = resample(CommuteAtlanta)) # mean commute time in another resample
mean(~Time, data = resample(CommuteAtlanta))
```


### Bootstrap Distribution {-}

#### Figure 3.16 {-}

The example below uses data from 500 Atlanta commuters.
```{r Figure3.16, cache=TRUE}
# Now we'll do it 1000 times
Bootstrap <- do(1000) * mean( ~Time, data = resample(CommuteAtlanta))
head(Bootstrap, 3)
# We should check that that our bootstrap distribution has an appropriate shape:
gf_dotplot( ~ mean, binwidth = 0.08, data = Bootstrap)
```


#### Example 3.19 {-}

```{r Example3.19, cache=TRUE, opts.label="fig4"}
BootP <- do(1000) * rflip(100, .52)
head(BootP, 3)
gf_dotplot(~ prop, binwidth = .002, data = BootP)
```


```{r Figure3.18, ref.label = "Example3.19", include=FALSE}
```


#### Example 3.20 {-}

Variables can be created in R  using the `c()` function then collected into
a data frame using the `data.frame()` function.
```{r Example3.20}
Laughter <- data.frame( NumLaughs =  c(16, 22, 9, 31, 6, 42) )
mean( ~ NumLaughs, data = Laughter )
```


```{r Example3.20b}
mean( ~NumLaughs, data = resample(Laughter))
mean( ~NumLaughs, data = resample(Laughter))
mean( ~NumLaughs, data = resample(Laughter))
```


### Estimating Standard Error Based on a Bootstrap Distribution {-}

#### Example 3.21 {-}

Since the shape of the bootstrap distribution from Example 3.19 looks good, we can estimate the standard error.
```{r Example3.21}
SE <- sd(~prop, data = BootP); SE
```


### 95\%  Confidence Interval Based on a Bootstrap Standard Error {-}

#### Example 3.22 {-}
We can again use the standard error to compute a 95\<!--  confidence interval. -->
```{r Example3.22, tidy=FALSE}
x.bar <- mean(~Time, data = CommuteAtlanta); x.bar
SE <- sd( ~ mean, data = Bootstrap ); SE        # standard error
MoE <- 2 * SE; MoE                              # margin of error for 95<!--  CI -->
x.bar - MoE                                     # lower limit of 95<!--  CI -->
x.bar + MoE                                     # upper limit of 95<!--  CI -->
```


```{r Example3.22b}
p.hat <- 0.52
SE <- sd( ~prop, data = BootP); SE      
MoE <- 2 * SE; MoE                          
p.hat - MoE                                 
p.hat + MoE                                 
```

The steps used in this example get used in a wide variety of confidence interval situations.

<!-- begin enumerate -->

#. Compute the statistic from the original sample.
#. Create a bootstrap distribution by resampling from the sample.
	
	<!-- begin enumerate -->
	
    \(a\) same size samples as the original sample
    \(b\) with replacement
    \(c\) compute the statistic for each sample
		
	<!-- end enumerate -->
	
	The distribution of these statistics is the bootstrap distribution
#. Estimate the standard error $SE$ by computing the standard deviation of the bootstrap distribution.
#. 95% CI is \[ \mbox{statistic} \pm 2 SE \]
<!-- end enumerate -->


## Bootstrap Confidence Intervals Using Percentiles

### Confidence Intervals Based on Bootstrap Percentiles {-}

#### Example 3.23 {-}

Another way to create a 95\% confidence interval is to use the middle 95\% of the bootstrap distribution. The `cdata()` function can compute this for us as follows:
```{r Example3.23}
cdata( ~ mean, 0.95, data = Bootstrap)
```

This is not exactly the same as the interval of the original sample, but it is pretty close.

#### Figure 3.22 {-}

```{r Figure3.22}
gf_dotplot(~ mean, binwidth = .08, colour = ~(27.43 <= mean & mean <= 31.05), 
           data = Bootstrap, show.legend = FALSE)
```

Notice the <span style="color:brown">colour=</span> for marking the confidence interval.
<!-- AuthNote --- should a new variable be made? -->
#### Example 3.24 {-}

One advantage of this method is that it is easy to change the confidence level. 

To make a 90\% and 99\% confidence interval, we use the middle 90\% and 99\% of the sample distribution instead.
```{r Example3.24}
cdata(~ mean, 0.90, data = Bootstrap)
gf_dotplot(~ mean, binwidth = .08, colour = ~(27.70 <= mean & mean <= 30.71), 
           data = Bootstrap, show.legend = FALSE)

cdata( ~ mean, 0.99, data = Bootstrap)
gf_dotplot(~ mean, binwidth = .08, colour = ~(26.98 <= mean & mean <= 31.63), 
           data = Bootstrap, show.legend = FALSE)
```

<!-- AuthNote --- new variable? -->
```{r Figure3.23, ref.label = "Example3.23", include=FALSE}
```


### Finding Confidence Intervals for Many Different Parameters {-}

#### Figure 3.24 {-}

```{r Figure3.24}
gf_boxplot(Exercise~Gender, data=ExerciseHours)
```


#### Example 3.25 {-}

```{r Example3.25}
head(ExerciseHours)
favstats(~Exercise|Gender, data = ExerciseHours)
stat <- diffmean(Exercise~Gender, data = ExerciseHours); stat
```

```{r Example3.25b, cache=TRUE}
BootE <- do(3000) * diffmean(Exercise~Gender, data = resample(ExerciseHours))
head(BootE, 3)
```

```{r Example3.25c, opts.label="fig4"}
cdata( ~ diffmean, 0.95, data = BootE)
gf_dotplot(~ diffmean, binwidth = .20, dotsize = .45, 
           colour = ~(-1.717 <= diffmean & diffmean <= 7.633), 
           xlab = "Difference in mean", data = BootE, show.legend = FALSE)
```

```{r Example3.25d}
SE <- sd( ~ diffmean, data = BootE); SE
stat - 2 * SE
stat + 2 * SE
```

<!-- AuthNote --- original plot used variable 'M' but it was unrecognized. I assumed they wanted to filter 'diffmean', also should be count not density -->
#### Figure 3.26 {-}

```{r Figure3.26}
gf_point(Price~Miles, ylab = "Price ($1000s)", xlab = "Miles (1000s)", data = MustangPrice)
cor(Price~Miles, data = MustangPrice)
```


#### Example 3.26 {-}

```{r Example3.26, cache=TRUE}
BootM <- do(5000) * cor(Price~Miles, data = resample((MustangPrice)))
head(BootM, 3)
```

```{r Example3.26b, opts.label="fig4"}
cdata( ~ cor, 0.98, data = BootM)
gf_dotplot( ~ cor, binwidth = .002, colour = ~(-.940 <= cor & cor <= -.705), 
         xlab = "r", data = BootM, show.legend = FALSE)
```


```{r Figure3.27, ref.label = "Example3.26b", include=FALSE}
```


### Another Look at the Effect of Sample Size {-}

#### Example 3.27 {-}
```{r Example3.27, opts.label="fig4", cache=TRUE}
BootP400 <- do(1000) * rflip(400, .52)
head(BootP400, 3)
cdata( ~ prop, 0.95, data = BootP400)
gf_dotplot(~ prop, binwidth = 0.002, colour = ~(0.472 <= prop & prop<= 0.568),
           data = BootP400, show.legend = FALSE)
```

```{r Figure3.28, Example3.27, include=FALSE}
```


### One Caution on Constructing Bootstrap Confidence Intervals {-}

#### Example 3.28 {-}

```{r Example3.28, opts.label="fig4", cache=TRUE}
median(~ Price, data = MustangPrice )
Boot.Mustang <- do(5000) * median( ~Price, data = resample(MustangPrice) )
head(Boot.Mustang, 3)
gf_histogram( ~ median, bins = 50, data = Boot.Mustang)
```

```{r Figure3.29, ref.label = "Example3.28", include=FALSE}
```




This time the histogram does not have the desired shape.  There are two problems:
<!-- begin enumerate -->

#. The distribution is not symmetric. (It is right skewed.)
#. The distribution has spikes and gaps.

Since the median must be an element of the sample when the sample size is 25, there are only 25 possible values for the median (and some of these are _very_ unlikely. 
<!-- end enumerate -->

Since the bootstrap distribution does not look like a normal distribution (bell-shaped, symmetric), we cannot safely use our methods for creating a confidence interval.
