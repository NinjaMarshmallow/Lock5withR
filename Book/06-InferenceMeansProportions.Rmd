`r chapter <- 5`
```{r include=FALSE}
require(Lock5withR)
require(mosaic)
require(ggformula)
require("fastR")
```

# Inference for Means and Proportions

## Distribution of a Sample Proportion

When sampling distributions, bootstrap distributions, and randomization distributions are well approximated by normal distributions, and when we have a way of computing the standard error, we can use normal distributions to compute confidence intervals and p-values using the following general templates:

<span class="itemize"> 

#. confidence interval: 
		\[ 
		\mbox{statistic} \pm \mbox{critical value} \cdot  SE 
		\]

#. hypothesis testing: 
		\[ 
		\mbox{test statistic} = \frac{ \mbox{statistic} - \mbox{null parameter}} { SE } 
		\]
</span> 

#### Example 6.1 {-}

```{r Example6.1}
SE <- sqrt(0.25 *(1 - 0.25) / 50); SE
SE <- sqrt(0.25 *(1 - 0.25) / 200); SE
SE <- sqrt(0.4 *(1 - 0.4) / 50); SE
```


### How Large a Sample Size is Needed? {-}

#### Figure 6.2 {-}

```{r Figure6.02, cache=TRUE, opts.label="fig3"}
P.05 <- do(2000) * rflip(50, .05)
gf_dotplot(~prop, binwidth = .01, dotsize = .02, data = P.05)

P.10 <- do(2000) * rflip(50, .10)
gf_dotplot(~prop, binwidth = .01, dotsize = .04, data = P.10)

P.25 <- do(2000) * rflip(50, .25)
gf_dotplot(~prop, binwidth = .01, dotsize = .08, data = P.25)

P.50 <- do(2000) * rflip(50, .50)
gf_dotplot(~prop, binwidth = .01, dotsize = .1, data = P.50)

P.90 <- do(2000) * rflip(50, .90)
gf_dotplot(~prop, binwidth = .01, dotsize = .03, data = P.90)

P.99 <- do(2000) * rflip(50, .99)
gf_dotplot(~prop, binwidth = .01, dotsize = .004, data = P.99)
```

<!-- AuthNote --- changed binwidth so may be different than book, count became density -->
#### Figure 6.3 {-}

```{r Figure6.03, cache=TRUE, opts.label="fig3"}
n10 <- do(2000) * rflip(10, .10)
gf_dotplot(~prop, binwidth = .02, dotsize = .018, data = n10)
n25 <- do(2000) * rflip(25, .10)
gf_dotplot(~prop, binwidth = .03, dotsize = .013, data = n25)
n200 <- do(2000) * rflip(200, .10)
gf_dotplot(~prop, binwidth = .006, dotsize = .03, data = n200)
```

<!-- AuthNote --- changed binwidth, count became density -->
#### Example 6.2 {-}

```{r Example6.2, tidy=FALSE}
p.hat <- 0.80; p.hat
p.hat * 400               # check >= 10
(1 - p.hat) * 400         # check >= 10
SE <- sqrt(.80 * .20 / 400); SE
```


#### Figure 6.4 {-}

```{r Figure6.4}
gf_fun(dnorm(x,0.80,0.02) ~ x, xlim = c(0.72, 0.88))
```



## Confidence Interval for a Single Proportion

### Confidence Interval for a Single Proportion {-}

#### Example 6.3 {-}

```{r Example6.3, tidy=FALSE}
p.hat <- 52/100; p.hat            
SE <- sqrt(p.hat * (1 - p.hat) / 100); SE    # est. SE
p.hat - 1.96 * SE                            # lower end of CI 
p.hat + 1.96 * SE                            # upper end of CI
```


R  can automate finding the confidence interval. Notice the <span style="color:brown">correct = FALSE</span> in the second line. The default for the proportion test includes a continuity correction for more accurate results. You can perform the test without the correction for answers closer to the ones in the textbook.
```{r Example6.3b}
confint(prop.test(52, 100))
confint(prop.test(52, 100, correct = FALSE))
```



#### Example 6.4 {-}

```{r Example6.4, tidy=FALSE}
p.hat <- 0.28; p.hat            
SE <- sqrt(p.hat * (1 - p.hat) / 800); SE    # est. SE
p.hat - 1.96 * SE                            # lower end of CI 
p.hat + 1.96 * SE                            # upper end of CI
confint(prop.test(224, 800))                 # 224 = 0.28 * 800
```


```{r Example6.4b, tidy=FALSE}
p.hat <- 0.82; p.hat            
SE <- sqrt(p.hat * (1 - p.hat) / 800); SE    # est. SE
p.hat - 1.96 * SE                            # lower end of CI 
p.hat + 1.96 * SE                            # upper end of CI
confint(prop.test(656, 800))                 # 656 = 0.82 * 800
```


### Determining Sample Size for Estimating a Proportion {-}

#### Example 6.5 {-}

```{r Example6.5}
z.star <- qnorm(0.995); z.star               # critical value for 99<!--  confidence -->
p.hat <- 0.28; p.hat                          
n <- ((z.star / 0.01)^2) * p.hat * (1 - p.hat); n                          
```


#### Example 6.6 {-}

```{r Example6.6}
z.star <- qnorm(0.975); z.star               # critical value for 95<!--  confidence -->
p.hat <- 0.5; p.hat                          
n <- ((z.star / 0.03)^2) * p.hat * (1 - p.hat); n                          
```



## Test for a Single Proportion

#### Example 6.7 {-}

<span class="enumerate">

#. $H_0$: $p = 0.20$
    
    $H_a$: $p < 0.20$
#. Test statistic:  $\hat p = 0.19$ (the sample approval rating)
#. Test for a single proportion:

```{r Example6.7}
p.hat <- 0.19; p.hat
p <- 0.20; p
p * 1013                   # check >= 10
(1 - p) * 1013             # check >= 10
SE <- sqrt(p * (1 - p) / 1013); SE
z <- (p.hat - p) / SE; z
pnorm(z)
```

Again, R  can automate the test for us.
```{r Example6.7b}
prop.test(192, 1013, alt = "less", p = 0.20) # 192 = 0.19 * 1013
```

Notice the "less" for the alternative hypothesis because this is a lower tail alternative.
</span>

#### Example 6.8 {-}

```{r Example6.8, tidy=FALSE}
p.hat <- 66/119; p.hat
p <- 1/3; p
p * 119                   # check >= 10
(1 - p) * 119             # check >= 10
SE <- sqrt(p * (1 - p) / 119); SE
z <- (p.hat - p) / SE; z
pnorm(z)                  # large side (rounded)
1 - pnorm(z)              # small side (less rounding)
2 * (1 - pnorm(z))        # p-value = 2 * small side
prop.test(66, 119, p = 1/3)
```


#### Example 6.9 {-}

```{r Example6.9}
p.hat <- 8/9; p.hat
p <- 0.5; p
p * 9                   # check >= 10
```


```{r Example6.9b, cache=TRUE}
Randomization <- do(1000) * rflip(9, 0.5)
head(Randomization, 3)
prop( ~ (prop >= p.hat), data = Randomization)
```


## Distribution of a Sample Mean

### Computing the Standard Error {-}

#### Example 6.10 {-}

```{r Example6.10}
SE <- 32000 / sqrt(100); SE
SE <- 32000 / sqrt(400); SE
```


### How Large a Sample Size is Needed? {-}

#### Figure 6.6 {-}
```{r Figure6.06,cache=TRUE,opts.label="fig3"}
n1 <- do(100) * mean( ~ Time, data = resample(CommuteAtlanta, 1))
gf_dhistogram( ~ mean, bins = 8, data = n1)
n5 <- do(100) * mean( ~ Time, data = resample(CommuteAtlanta, 5))
gf_dhistogram( ~ mean, bins = 8, data = n5)
n15 <- do(100) * mean( ~ Time, data = resample(CommuteAtlanta, 15))
gf_dhistogram( ~ mean, bins = 8, data = n15)
n30 <- do(100) * mean( ~ Time, data = resample(CommuteAtlanta, 30))
gf_dhistogram( ~ mean, bins = 8, data = n30)
n125 <- do(100) * mean( ~ Time, data = resample(CommuteAtlanta, 125))
gf_dhistogram( ~ mean, bins = 8, data = n125)
n500 <- do(100) * mean( ~ Time, data = resample(CommuteAtlanta, 500))
gf_dhistogram( ~ mean, bins = 8, data = n500)
```

<!-- AuthNote --- histograms in lattice but dotplots in book -->
### The t-Distribution {-}

If we are working with one quantitative variable, we can compute confidence intervals and p-values
using the following standard error formula:
\[
SE = \frac{\sigma}{ \sqrt{n}} 
\]
Once again, there is a small problem: we won't know $\sigma$.  So we will estimate $\sigma$ using our data:
\[
\displaystyle SE \approx \frac{s}{\sqrt{n}}
\]
Unfortunately, the distribution of 
\[
\frac{\mean x - \mu}{ s/\sqrt{n}}
\]
does not have a normal distribution.  Instead the distribution is a bit ``shorter and fatter" than the normal
distribution.  The correct distribution is called the t-distribution with $n-1$ degrees of freedom. 
All t-distributions are symmetric and centered at zero.  The smaller the degrees of freedom, the shorter and fatter 
the t-distribution.

#### Example 6.11 {-}

```{r Example6.11}
df <- 50 - 1; df
SE <- 10.5 / sqrt (50); SE
```

```{r Example6.11b}
df <- 8 - 1; df
SE <- 1.25 / sqrt (8); SE
```


#### Figure 6.8 {-}

```{r Figure6.08, fig.keep='last'}
gf_fun(dnorm(x, 0, 1) ~x, xlim = c(-4, 4), colour = "black") %>%
gf_fun(dt(x, df = 15) ~x, xlim = c(-4, 4), colour = 'green') %>%
gf_fun(dt(x, df = 5) ~x, xlim = c(-4, 4), colour = "red")
```


#### Example 6.12 {-}

```{r Example6.12}
qt(.975, df = 15)
pt(1.5, df = 15, lower.tail = FALSE)
```

Similar to the normal distribution, the function for t-distribution is set to find probability of the lower tail.

```{r Example6.12b}
qnorm(.975)
pnorm(1.5, lower.tail = FALSE)
```


#### Figure 6.9 {-}

```{r Figure6.09,fig.keep='last'}
gf_fun(dt(x, df = 15) ~x, xlim = c(-4, 4)) %>%
  gf_vline(xintercept = ~c(2.131,-2.131))
```

<!-- AuthNote --- add label for vline on 2.131 -->
```{r Figure6.09b,fig.keep='last'}
gf_fun(dt(x, df = 15) ~x, xlim = c(-4, 4)) %>%
  gf_vline(xintercept = 1.5)
```

<!-- AuthNote --- add label for vline on 1.5 -->
## Confidence Interval for a Mean Using the t-Distribution

### Confidence Interval for a Mean Using the t-Distribution {-}

#### Example 6.13 {-}

```{r Example6.13}
head(Flight179, 3)
gf_dotplot(~Flight179, binwidth = 12, dotsize = 0.3, data = Flight179) #to check for normality
```

<!-- AuthNote --- irregular binwidth -->

```{r Figure6.11,include=FALSE, ref.label = "Example6.13" }

```



RStudio  can do all of the calculations for you if you give it the raw data:
```{r Example6.13b}
favstats(~Flight179, data = Flight179)
t.test(~Flight179, data = Flight179)
```


You can also zoom in just the information you want:
```{r Example6.13c}
confint(t.test(~Flight179, data = Flight179))
```


#### Example 6.14 {-}

```{r Example6.14}
head(CommuteAtlanta, 3)
gf_dens(~Time, data = CommuteAtlanta) # to check for normality
```

```{r Example6.14b}
favstats(~Time, data = CommuteAtlanta)
confint(t.test(~Time, conf.level = 0.99, data = CommuteAtlanta))
confint(t.test(~Time, conf.level = 0.95, data = CommuteAtlanta))
```


\subsubsection*{Example 6.15}

```{r Example6.15, opts.label="fig1"}
head(ManhattanApartments, 3)
gf_dotplot(~Rent, binwidth = 200, dotsize = 1, data = ManhattanApartments) # to check for normality
```

<!-- AuthNote --- irregular bins -->

```{r Figure6.13,include=FALSE, ref.label = "Example6.15" }

```


```{r Example6.15b, cache=TRUE}
Boot.Rent <- do(1000) * mean( ~ Rent, data = resample(ManhattanApartments)) 
head(Boot.Rent, 3)
favstats( ~ mean, data = Boot.Rent)
cdata( ~ mean, 0.95, data = Boot.Rent)
```


### Determining Sample Size for Estimating a Mean {-}

#### Example 6.16 {-}
```{r Example6.16}
n <- (1.96 * 20.18 / 2) ^ 2; n
```



## Test for a Single Mean

#### Example 6.17 {-}
```{r Example6.17, opts.label="fig1"}
head(BodyTemp50)
gf_dotplot(~BodyTemp, dotsize = 1, binwidth = .1, stackratio = 2, data = BodyTemp50) # to check for normality
```


```{r Figure6.16,include=FALSE, ref.label = "Example6.17" }

```


```{r Example6.17b}
favstats(~BodyTemp, data = BodyTemp50)
t.test(~BodyTemp, mu = 98.6, data = BodyTemp50)
pval(t.test(~BodyTemp, mu = 98.6, data = BodyTemp50)) # to find the p-value directly
```


#### Figure 6.17 {-}

```{r Figure6.17,fig.keep='last'}
plotFun(dt(x, df = 49) ~x, x.lim = c(-4, 4))
plotDist("t", params = list(df=49), type = c("h","l"), groups = (-3.14 < x & x < 3.14), lty = 1)
ladd(grid.text("3.14",3,.05, default.units = "native", hjust = 0))

gf_fun(dt(x, df = 49) ~x, xlim = c(-4, 4)) %>%
  gf_vline(xintercept = ~c(-3.14, 3.14))
```

<!-- AuthNote --- label vline at 3.14 -->
#### Example 6.18 {-}
```{r Example6.18}
head(FloridaLakes, 3)
gf_dens(~Alkalinity, data = FloridaLakes) # to check for normality
```


```{r Example6.18b}
favstats(~Alkalinity, data = FloridaLakes)
t.test(~Alkalinity, alt = "greater", mu = 35, data = FloridaLakes)
```

Notice the "greater" for the alternative hypothesis.

## Distribution of Differences in Proportions

#### Example 6.19 {-}

```{r Example6.19}
OneTrueLove <- read.file("OneTrueLove.csv")
head(OneTrueLove)
tally(Response~Gender, format = "count", margins = TRUE, data = OneTrueLove)
prop(Response~Gender, data = OneTrueLove)
diff(prop(Response~Gender, data = OneTrueLove))
```


#### Figure 6.20 {-}

```{r Figure6.20, cache=TRUE}
Boot.Love <- do(5000)*diff(prop(Response~Gender, data = resample(OneTrueLove)))
head(Boot.Love, 3)
gf_dhistogram(~ prop_Agree.Male, data = Boot.Love) %>%
  gf_fitdistr()
```


#### Example 6.20 {-}
```{r Example6.20}
SE <- sqrt(0.257*(1-0.257)/1412 + 0.307*(1-0.307)/1213); SE
```



## Confidence Interval for a Difference in Proportions

#### Data 6.3 {-}

```{r Data6.3}
success <- c(158, 109)
n <- c(444,922)
```


#### Example 6.21 {-}

```{r Example6.21}
success <- c(158, 109)
n <- c(444,922)
prop.test(success, n, conf.level = 0.90)
```



## Test For a Difference in Proportions

#### Data 6.4 {-}

```{r Data6.4, tidy=FALSE}
SplitSteal <- rbind( 
  do(187) * data.frame(agegroup = "Under40", decision = "Split"),
  do(195) * data.frame(agegroup = "Under40", decision = "Steal"),
  do(116) * data.frame(agegroup = "Over40",  decision = "Split"),
  do(76)  * data.frame(agegroup = "Over40",  decision = "Steal")
  )
```


#### Example 6.22 {-}

```{r Example6.22}
prop(decision~agegroup, data = SplitSteal) # sample prop within each group
prop(~decision, data = SplitSteal) # pooled proportion
```


#### Example 6.23 {-}

```{r Example6.23}
diff <- diff(prop(decision~agegroup, data = SplitSteal)); diff
prop.test(decision~agegroup, data = SplitSteal)
```



## Distribution of Differences in Means

#### Figure 6.21 {-}

```{r Figure6.21, cache=TRUE}
BootE <- do(2000) * diff(mean(Exercise~Gender, data = resample(ExerciseHours)))
head(BootE, 3)
gf_dhistogram(~M, binwidth = .5, data = BootE) %>%
  gf_fitdistr()
```


```{r Figure6.21b, cache=TRUE}
Random.Smiles <- do(2000) * diff(mean(Leniency ~ shuffle(Group), data = Smiles))
head(Random.Smiles, 3)
gf_dhistogram(~smile, bins = 24, data = Random.Smiles) %>%
  gf_fitdistr()
```


### The t-Distribution {-}

#### Example 6.24 {-}

```{r Example6.24}
favstats(Exercise~Gender, data = ExerciseHours)
SE <- sqrt(8.80^2/20 + 7.41^2/30); SE
favstats(Leniency~Group, data = Smiles)
SE <- sqrt(1.68^2/34 + 1.52^2/34); SE
```


<!-- Example 6.25 -->


## Confidence Interval for a Difference in Means

#### Example 6.26 {-}

```{r Example6.26}
head(CommuteStLouis)
favstats(~Time, data = CommuteStLouis)
favstats(~Time, data = CommuteAtlanta)
gf_boxplot(Time ~ ", x = ", xlim = c(0, 200), data = CommuteAtlanta) %>%
  gf_refine(coord_flip()) # to check for normality
gf_boxplot(Time ~ ", x = ", xlim = c(0, 200), data = CommuteStLouis) %>%
  gf_refine(coord_flip()) # to check for normality
```


```{r Figure6.23,include=FALSE, ref.label = "Example6.26" }

```


```{r Example6.26b}
confint(t.test(CommuteAtlanta$Time, CommuteStLouis$Time, conf.level = 0.90))
```



## Test for a Difference in Means

#### Example 6.27 {-}

```{r Example6.27}
head(Smiles, 3)
gf_boxplot(Leniency~Group, data = Smiles) %>%
  gf_refine(coord_flip()) # to check for normality
```


```{r Figure6.25,include=FALSE, ref.label = "Example6.27" }

```



```{r Example6.27b}
t.test(Leniency~Group, alt = "less", data = Smiles)
```



## Paired Difference in Means

#### Example 6.28 {-}

```{r Example6.28, opts.label="fig1", message = FALSE, warning = FALSE}
head(Wetsuits, 3)
gf_dotplot(~ Wetsuit, xlim = c(1.1, 1.8), binwidth = .04, dotsize = .8, data = Wetsuits) # to check for normality
gf_dotplot(~ NoWetsuit, xlim = c(1.1, 1.8), binwidth = .04, dotsize = .8, data = Wetsuits) # to check for normality
```

<!-- AuthNote --- irregular bin -->

```{r Figure6.27,include=FALSE, ref.label = "Example6.28" }

```


```{r Example6.28b}
t.test(Wetsuits$Wetsuit, Wetsuits$NoWetsuit)
```


#### Example 6.29 {-}

```{r Example6.29, opts.label="fig1"}
head(Wetsuits, 3)
t.test(Wetsuits$Wetsuit, Wetsuits$NoWetsuit, paired = TRUE)
gf_dotplot(~(Wetsuit - NoWetsuit), binwidth = .01, dotsize = .4, data = Wetsuits)
```


```{r Figure6.28,include=FALSE, ref.label = "Example6.29" }

```

#### Example 6.30 {-}

```{r Example6.30}
confint(t.test(Wetsuits$Wetsuit, Wetsuits$NoWetsuit, paired = TRUE))
confint(t.test( ~ (Wetsuit - NoWetsuit), data = Wetsuits))
```